# 3. LGTM Observability Stack Manual Deployment

## Overview
The LGTM (Loki, Grafana, Tempo, Mimir) Observability Stack provides comprehensive monitoring, logging, and tracing for the EKS cluster.

## Prerequisites
- Foundation workflow completed successfully
- Ingress workflow completed successfully
- kubectl configured for the EKS cluster
- Helm 3.x installed

## Components
- **Prometheus & Mimir**: Metrics collection and long-term storage
- **Loki**: Log aggregation and storage
- **Tempo**: Distributed tracing
- **Grafana**: Visualization and dashboards

## Manual Deployment Steps

### 1. Create Observability Namespace
```bash
kubectl create namespace observability
kubectl label namespace observability app.kubernetes.io/managed-by=manual
```

### 2. Deploy Prometheus with Mimir
```bash
# Add Prometheus Helm repository
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update

# Deploy kube-prometheus-stack
helm install prometheus prometheus-community/kube-prometheus-stack \
  --namespace observability \
  --version 51.9.4 \
  --set prometheus.prometheusSpec.storageSpec.volumeClaimTemplate.spec.resources.requests.storage=50Gi \
  --set prometheus.prometheusSpec.retention=30d \
  --set alertmanager.alertmanagerSpec.storage.volumeClaimTemplate.spec.resources.requests.storage=10Gi \
  --set grafana.enabled=true \
  --set grafana.persistence.enabled=true \
  --set grafana.persistence.size=10Gi
```

### 3. Deploy Loki
```bash
# Add Grafana Helm repository
helm repo add grafana https://grafana.github.io/helm-charts
helm repo update

# Deploy Loki
helm install loki grafana/loki \
  --namespace observability \
  --version 5.22.0 \
  --set loki.persistence.enabled=true \
  --set loki.persistence.size=50Gi \
  --set loki.config.storage_config.aws.region=us-east-1
```

### 4. Deploy Promtail
```bash
# Deploy Promtail for log collection
helm install promtail grafana/promtail \
  --namespace observability \
  --version 6.13.1 \
  --set config.lokiAddress=http://loki:3100/loki/api/v1/push
```

### 5. Deploy Tempo
```bash
# Deploy Tempo for distributed tracing
helm install tempo grafana/tempo \
  --namespace observability \
  --version 1.5.1 \
  --set persistence.enabled=true \
  --set persistence.size=50Gi
```

### 6. Configure Grafana Datasources
```bash
# Get Grafana admin password
kubectl get secret prometheus-grafana -n observability -o jsonpath="{.data.admin-password}" | base64 --decode

# Port-forward to access Grafana UI
kubectl port-forward svc/prometheus-grafana 3000:80 -n observability
```

Access Grafana at http://localhost:3000 (admin/password from above) and configure:
- Prometheus datasource: http://prometheus-kube-prometheus-prometheus:9090
- Loki datasource: http://loki:3100
- Tempo datasource: http://tempo:3100

## Verification Steps

### 1. Check Pod Status
```bash
kubectl get pods -n observability
```

### 2. Check Services
```bash
kubectl get svc -n observability
```

### 3. Check PVCs
```bash
kubectl get pvc -n observability
```

### 4. Test Metrics Collection
```bash
# Port-forward to Prometheus
kubectl port-forward svc/prometheus-kube-prometheus-prometheus 9090:9090 -n observability

# Access Prometheus at http://localhost:9090
# Query: up{job="kubernetes-nodes"}
```

### 5. Test Log Collection
```bash
# Port-forward to Loki
kubectl port-forward svc/loki 3100:3100 -n observability

# Test log query
curl -G -s "http://localhost:3100/loki/api/v1/query" --data-urlencode 'query={job="kubernetes-pods"}'
```

## Cost Considerations
- **Storage**: ~150Gi of persistent storage required (~$15/month)
- **Compute**: Moderate CPU/memory overhead (~$20-30/month)
- **Total estimated cost**: ~$35-45/month

## Troubleshooting

### Common Issues
1. **Storage Issues**: Ensure sufficient EBS storage quota
2. **Memory Issues**: Consider increasing node memory if pods are OOMKilled
3. **Network Issues**: Verify security groups allow pod-to-pod communication

### Log Analysis
```bash
# Check Prometheus logs
kubectl logs -f deployment/prometheus-kube-prometheus-operator -n observability

# Check Loki logs
kubectl logs -f deployment/loki -n observability

# Check Grafana logs
kubectl logs -f deployment/prometheus-grafana -n observability
```

## Cleanup
```bash
helm uninstall prometheus -n observability
helm uninstall loki -n observability
helm uninstall promtail -n observability
helm uninstall tempo -n observability
kubectl delete namespace observability
```

## Notes
- This stack provides comprehensive observability but requires significant resources
- Consider using AWS managed services (CloudWatch, X-Ray) for production workloads
- Storage costs can be optimized by adjusting retention policies