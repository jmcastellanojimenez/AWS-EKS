# ArgoCD Production Configuration
# Integrates with Ambassador ingress and LGTM observability stack

## Global Configuration
global:
  # Domain will be configured during installation
  domain: ${ARGOCD_DOMAIN:-argocd.local}
  image:
    repository: quay.io/argoproj/argocd
    tag: v2.10.0

## ArgoCD Server Configuration
server:
  name: argocd-server
  replicas: 2
  
  # Auto-scaling configuration
  autoscaling:
    enabled: true
    minReplicas: 2
    maxReplicas: 5
    targetCPUUtilizationPercentage: 70
    targetMemoryUtilizationPercentage: 80
  
  # Resource configuration
  resources:
    requests:
      cpu: 100m
      memory: 256Mi
    limits:
      cpu: 500m
      memory: 512Mi
  
  # Service configuration
  service:
    type: ClusterIP
    port: 80
    portName: http
    annotations:
      prometheus.io/scrape: "true"
      prometheus.io/port: "8080"
      prometheus.io/path: "/metrics"
  
  # Ingress configuration for Ambassador
  ingress:
    enabled: true
    ingressClassName: ""
    annotations:
      kubernetes.io/ingress.class: "ambassador"
      getambassador.io/config: |
        ---
        apiVersion: getambassador.io/v3alpha1
        kind: Mapping
        name: argocd-server
        prefix: /
        service: argocd-server:80
        host: ${ARGOCD_DOMAIN}
        timeout_ms: 30000
    hosts:
      - ${ARGOCD_DOMAIN}
    tls:
      - secretName: argocd-server-tls
        hosts:
          - ${ARGOCD_DOMAIN}

## Application Controller Configuration
controller:
  name: argocd-application-controller
  replicas: 1
  
  # Resource configuration
  resources:
    requests:
      cpu: 250m
      memory: 512Mi
    limits:
      cpu: 2000m
      memory: 2Gi
  
  # Metrics configuration
  metrics:
    enabled: true
    serviceMonitor:
      enabled: true
      selector:
        prometheus: kube-prometheus

## Repository Server Configuration
repoServer:
  name: argocd-repo-server
  replicas: 2
  
  # Auto-scaling configuration
  autoscaling:
    enabled: true
    minReplicas: 2
    maxReplicas: 4
    targetCPUUtilizationPercentage: 70
  
  # Resource configuration
  resources:
    requests:
      cpu: 100m
      memory: 256Mi
    limits:
      cpu: 1000m
      memory: 1Gi
  
  # Metrics configuration
  metrics:
    enabled: true
    serviceMonitor:
      enabled: true

## Redis Configuration
redis:
  enabled: true
  
  # Resource configuration
  resources:
    requests:
      cpu: 100m
      memory: 128Mi
    limits:
      cpu: 200m
      memory: 256Mi

## Redis HA Configuration
redis-ha:
  enabled: true
  
  # Persistence configuration
  persistentVolume:
    enabled: true
    size: 8Gi
    storageClass: gp3
  
  # Redis configuration
  redis:
    resources:
      requests:
        cpu: 100m
        memory: 200Mi
      limits:
        cpu: 300m
        memory: 400Mi
  
  # Sentinel configuration
  sentinel:
    resources:
      requests:
        cpu: 100m
        memory: 200Mi
      limits:
        cpu: 300m
        memory: 400Mi

## ApplicationSet Controller
applicationSet:
  enabled: true
  
  # Resource configuration
  resources:
    requests:
      cpu: 100m
      memory: 128Mi
    limits:
      cpu: 500m
      memory: 512Mi
  
  # Metrics configuration
  metrics:
    enabled: true
    serviceMonitor:
      enabled: true

## Notifications Controller
notifications:
  enabled: true
  
  # Resource configuration
  resources:
    requests:
      cpu: 100m
      memory: 128Mi
    limits:
      cpu: 500m
      memory: 512Mi
  
  # Metrics configuration
  metrics:
    enabled: true
    serviceMonitor:
      enabled: true

## Dex Configuration (OIDC)
dex:
  enabled: false  # Configure externally if needed
  
  # Resource configuration
  resources:
    requests:
      cpu: 50m
      memory: 64Mi
    limits:
      cpu: 200m
      memory: 256Mi

## Configuration Management
configs:
  # ArgoCD configuration
  cm:
    # Server configuration
    url: https://${ARGOCD_DOMAIN}
    application.instanceLabelKey: argocd.argoproj.io/instance
    
    # OIDC configuration (if using external OIDC)
    oidc.config: |
      name: OIDC
      issuer: ${OIDC_ISSUER_URL}
      clientId: ${OIDC_CLIENT_ID}
      clientSecret: ${OIDC_CLIENT_SECRET}
      requestedScopes: ["openid", "profile", "email", "groups"]
    
    # Resource customizations
    resource.customizations: |
      networking.k8s.io/Ingress:
        health.lua: |
          hs = {}
          hs.status = "Healthy"
          return hs
  
  # RBAC configuration
  rbac:
    policy.default: role:readonly
    policy.csv: |
      # Admin users
      p, role:admin, applications, *, */*, allow
      p, role:admin, clusters, *, *, allow
      p, role:admin, repositories, *, *, allow
      
      # Developer users
      p, role:developer, applications, get, */*, allow
      p, role:developer, applications, sync, */*, allow
      p, role:developer, applications, action/*, */*, allow
      p, role:developer, logs, get, */*, allow
      
      # Readonly users
      p, role:readonly, applications, get, */*, allow
      p, role:readonly, logs, get, */*, allow
      
      # Group mappings (configure based on your OIDC groups)
      g, ecotrack:admin, role:admin
      g, ecotrack:developer, role:developer
      g, ecotrack:viewer, role:readonly

## Security Configuration
securityContext:
  runAsNonRoot: true
  runAsUser: 999
  runAsGroup: 999
  fsGroup: 999

## Service Account Configuration
serviceAccount:
  create: true
  annotations:
    # IRSA annotation will be added by Terraform
    eks.amazonaws.com/role-arn: ${ARGOCD_IRSA_ROLE_ARN}

## Monitoring Integration
metrics:
  enabled: true
  
  # Service monitors for Prometheus
  serviceMonitor:
    enabled: true
    selector:
      prometheus: kube-prometheus
    namespace: observability
    
  # Grafana dashboard
  grafana:
    enabled: true
    namespace: observability